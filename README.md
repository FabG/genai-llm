# Gen AI LLM

This repo inclueds courses, code snippets from various sources to better learn and build an intuition about Large Language Models
I first enrolled in a course from Deeplearning.ai called [Generative AI with Large Language Models](https://www.coursera.org/learn/generative-ai-with-llms) Course from AWS and Deeplearning.ai.
The main reason is my prior experience with Deeplearnin.ai as I gained a lot of knowledge from 2 prior courses from Andrew Ng and his team, namely: 
 - [Machine Learning specialization](https://www.deeplearning.ai/courses/machine-learning-specialization/)
 - [Deep Learning specialization](https://www.deeplearning.ai/courses/deep-learning-specialization/)

### Courses - Generative AI with Large Language Model
 - Course 1
  - [1 - Transformer intro and arch](genai-with-llm-course/course1/1_transformer_intro_arch.md)
  - [2 - Generating Text with Transformers](genai-with-llm-course/course1/2_text_generation_transformer.md)
  - [3 - Attention is All you need (paper)](genai-with-llm-course/course1/3_attention_is_all_you_need.md)
  - [4 - Prompt Engineering](genai-with-llm-course/course1/4_prompt_engineering.md)





### Notebooks and code snippet

### Credits and Resources
#### Courses
 - [Generative AI with Large Language Models](https://www.coursera.org/learn/generative-ai-with-llms) Course from AWS and Deeplearning.ai

#### Papers
 - [Attention is All You Need](https://arxiv.org/abs/1706.03762) Google and Toronto University papaer introducing the Transformer architecture
 - [Transfomer: A Novel Neural Network Architecture for Language understanding](https://blog.research.google/2017/08/transformer-novel-neural-network.html) Google Blog
